2025-03-28 14:30:51,620 INFO    Thread-8 (process_request_thread):2196 [wandb_setup.py:_flush():67] Current SDK version is 0.19.8
2025-03-28 14:30:51,620 INFO    Thread-8 (process_request_thread):2196 [wandb_setup.py:_flush():67] Configure stats pid to 2196
2025-03-28 14:30:51,621 INFO    Thread-8 (process_request_thread):2196 [wandb_setup.py:_flush():67] Loading settings from C:\Users\Asus\.config\wandb\settings
2025-03-28 14:30:51,621 INFO    Thread-8 (process_request_thread):2196 [wandb_setup.py:_flush():67] Loading settings from C:\Users\Asus\Downloads\Call_Agent_AI-demo_alpha\Call_Agent_AI-demo\backend\wandb\settings
2025-03-28 14:30:51,621 INFO    Thread-8 (process_request_thread):2196 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-03-28 14:30:51,621 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:setup_run_log_directory():647] Logging user logs to C:\Users\Asus\Downloads\Call_Agent_AI-demo_alpha\Call_Agent_AI-demo\backend\wandb\run-20250328_143051-8f9g2djq\logs\debug.log
2025-03-28 14:30:51,622 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:setup_run_log_directory():648] Logging internal logs to C:\Users\Asus\Downloads\Call_Agent_AI-demo_alpha\Call_Agent_AI-demo\backend\wandb\run-20250328_143051-8f9g2djq\logs\debug-internal.log
2025-03-28 14:30:51,622 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:init():761] calling init triggers
2025-03-28 14:30:51,622 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:init():766] wandb.init called with sweep_config: {}
config: {'_wandb': {}}
2025-03-28 14:30:51,622 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:init():784] starting backend
2025-03-28 14:30:51,622 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:init():788] sending inform_init request
2025-03-28 14:30:51,692 INFO    Thread-8 (process_request_thread):2196 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=spawn, using: spawn
2025-03-28 14:30:51,692 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:init():798] backend started and connected
2025-03-28 14:30:51,693 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:init():891] updated telemetry
2025-03-28 14:30:51,697 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:init():915] communicating run to backend with 90.0 second timeout
2025-03-28 14:30:52,666 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:init():990] starting run threads in backend
2025-03-28 14:30:52,866 INFO    Thread-8 (process_request_thread):2196 [wandb_run.py:_console_start():2375] atexit reg
2025-03-28 14:30:52,866 INFO    Thread-8 (process_request_thread):2196 [wandb_run.py:_redirect():2227] redirect: wrap_raw
2025-03-28 14:30:52,866 INFO    Thread-8 (process_request_thread):2196 [wandb_run.py:_redirect():2292] Wrapping output streams.
2025-03-28 14:30:52,866 INFO    Thread-8 (process_request_thread):2196 [wandb_run.py:_redirect():2315] Redirects installed.
2025-03-28 14:30:52,870 INFO    Thread-8 (process_request_thread):2196 [wandb_init.py:init():1032] run started, returning control to user process
2025-03-28 14:30:53,877 INFO    Thread-8 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:31:07,772 INFO    Thread-12 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:31:09,336 INFO    Thread-12 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:31:25,684 INFO    Thread-18 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:31:27,086 INFO    Thread-18 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:31:43,436 INFO    Thread-24 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:31:44,866 INFO    Thread-24 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:32:02,509 INFO    Thread-30 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:32:04,085 INFO    Thread-30 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:32:20,358 INFO    Thread-36 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:32:22,001 INFO    Thread-36 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:36:56,789 INFO    Thread-47 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:37:12,696 INFO    Thread-49 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:37:17,753 INFO    Thread-49 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:37:40,077 INFO    Thread-55 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:37:41,821 INFO    Thread-55 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:38:05,697 INFO    Thread-61 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:38:07,599 INFO    Thread-61 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:38:24,829 INFO    Thread-67 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:38:26,439 INFO    Thread-67 (process_request_thread):2196 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-28 14:41:46,378 INFO    MsgRouterThr:2196 [mailbox.py:close():129] Closing mailbox, abandoning 1 handles.
